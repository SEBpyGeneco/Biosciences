{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "#%reload_ext tensorboard\n",
    "#log_folder = './logs9'\n",
    "#writer = SummaryWriter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data_dir = './Data'\n",
    "    \n",
    "    transform = transforms.Compose(\n",
    "    [transforms.Resize((300,300)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5],\n",
    "                         std=[0.5])])\n",
    "\n",
    "    trainSet = datasets.ImageFolder(data_dir + '/TrainSet', transform=transform)\n",
    "    print(len(trainSet))\n",
    "    #validSet = datasets.ImageFolder(data_dir + '/ValidSet', transform=transform)\n",
    "    #testSet = datasets.ImageFolder(data_dir + '/TestSet', transform=transform)\n",
    "\n",
    "    train = DataLoader(trainSet, batch_size=32, shuffle=True)\n",
    "    #valid = DataLoader(validSet, batch_size=32, shuffle=False)\n",
    "    #test = DataLoader(testSet, batch_size=32, shuffle=False)\n",
    "\n",
    "    return train#, valid,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def train_imshow():\n",
    "    classes = ('Bad', 'Good')\n",
    "    dataiter = iter(train_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    fig, axes = plt.subplots(figsize=(10, 4), ncols=5)\n",
    "    for i in range(5):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images[i].permute(1, 2, 0))\n",
    "        ax.title.set_text(' '.join('%5s' % classes[labels[i]]))\n",
    "    plt.show()\n",
    "\n",
    "train_loader= get_data()#, val_loader,test_loader \n",
    "train_imshow()\n",
    "print(len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1  = nn.Linear(in_features= 7*7*52, out_features= 4096)\n",
    "        self.fc2  = nn.Linear(in_features= 4096, out_features= 4096)\n",
    "        self.fc3 = nn.Linear(in_features=4096 , out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\"\n",
    "model = VGG16().to(device)\n",
    "model.train()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x41472 and 2548x4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\arnau\\Documents\\Projet_deep_learning\\VGG16.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/VGG16.ipynb#ch0000005?line=7'>8</a>\u001b[0m data\u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/VGG16.ipynb#ch0000005?line=8'>9</a>\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/VGG16.ipynb#ch0000005?line=10'>11</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/VGG16.ipynb#ch0000005?line=11'>12</a>\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/VGG16.ipynb#ch0000005?line=12'>13</a>\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\arnau\\Documents\\Projet_deep_learning\\VGG16.ipynb Cell 4'\u001b[0m in \u001b[0;36mVGG16.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/VGG16.ipynb#ch0000003?line=45'>46</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/VGG16.ipynb#ch0000003?line=46'>47</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/VGG16.ipynb#ch0000003?line=47'>48</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/VGG16.ipynb#ch0000003?line=48'>49</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, \u001b[39m0.5\u001b[39m) \u001b[39m#dropout was included to combat overfitting\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/VGG16.ipynb#ch0000003?line=49'>50</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/arnau/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x41472 and 2548x4096)"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss =0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    for data,label in train_loader:\n",
    "        data= data.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        label = label.unsqueeze(-1)\n",
    "        label = label.to(torch.float32)\n",
    "        loss = criterion(output,label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = ((output.argmax(dim=1)==label).float().mean())\n",
    "        epoch_accuracy += acc/len(train_loader)\n",
    "        epoch_loss += loss/len(train_loader)\n",
    "        \n",
    "    print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch+1, epoch_accuracy,epoch_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\arnau\\Documents\\Projet_deep_learning\\Deep.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/Deep.ipynb#ch0000006?line=1'>2</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/Deep.ipynb#ch0000006?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/Deep.ipynb#ch0000006?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/Deep.ipynb#ch0000006?line=5'>6</a>\u001b[0m         images, labels \u001b[39m=\u001b[39m data\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arnau/Documents/Projet_deep_learning/Deep.ipynb#ch0000006?line=6'>7</a>\u001b[0m         outputs \u001b[39m=\u001b[39m model(images)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        print(outputs)\n",
    "        predicted_targets = outputs.argmax(dim=1)\n",
    "        print(predicted_targets)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted_targets == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the validation images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

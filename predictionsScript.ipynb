{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "from sklearn.feature_extraction import image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Conv2d(64, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Dropout(p=0.3),\n",
    "           \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512 * 9 * 9, 1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1000, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_inference(H, E) :\n",
    "    # P(A|B) = (P(B|A)*P(A))/P(B)\n",
    "    # P(A|B) Probabilité à posteriori que l'hypothèse A0 soit vraie (ce que l'on cherche à calculer)\n",
    "    # P(B|A) Probabilité que l'hypothèse soit vraie, selon le résultat d'un évenement (paramètre E pour évenement)\n",
    "    # P(A) = Probabilité à prioiri que l'hypothèse A0 est vraie (paramètre H pour hypothèse)\n",
    "    # P(B) = Probabilité de l'évenement, indépendament de l'hypothèse\n",
    "         # En supposant que les seuls hypothèse sont A0 et A1 :\n",
    "         #P(B) = P(B|A0)*P(A0|B) + P(B|A1)\n",
    "        \n",
    "    # On ne fait pas très confiance à la preuve \n",
    "    confiance = 0.5\n",
    "    E = E*confiance + (1-confiance)/2\n",
    "    # biais\n",
    "    E = E*0.975\n",
    "    \n",
    "    \n",
    "    return (H * E) / (H * E + (1-H)*(1-E))\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=41472, out_features=1000, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=1000, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the trained model\n",
    "net = T.load(\"trained_net\")\n",
    "net.to('cpu')\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOneImage(path,img_name,size,number_patches,threshold):\n",
    "    \n",
    "    predicted_list = []\n",
    "    \n",
    "    # chargement de l'image\n",
    "    img = io.imread(path+\"/\"+img_name)\n",
    "    \n",
    "    #extraction des patchs\n",
    "    patches = image.extract_patches_2d(img, (size,size),max_patches=number_patches)\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    # pour chacun des patch\n",
    "    for i in range(len(patches)):\n",
    "        # on applique les mêmes transformations et conditions que pour les images du training\n",
    "        patches[i] = patches[i].astype('uint16')\n",
    "        m = np.mean(patches[i])\n",
    "        if (m>threshold) :\n",
    "            patch = Image.fromarray(patches[i])\n",
    "            patch = patch.convert(mode='RGB')\n",
    "            image_tensor = transform(patch)\n",
    "            image_tensor = image_tensor.unsqueeze_(0)\n",
    "            \n",
    "            # on donne le patch à notre trained model\n",
    "            output = net(image_tensor)\n",
    "            \n",
    "            # on récupère la probabilité que le patch soit issu d'une image de mitochondrie segmentée, \n",
    "            #selon l'algorithme\n",
    "            output = output[0].tolist()\n",
    "            confidence = F.softmax(T.tensor([[output[0],output[1]]],dtype=T.float),dim=1).tolist()[0][0]\n",
    "            predicted_list.append(confidence)\n",
    "                    \n",
    "        return predicted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOne_consistent(path,img_name,size,number_patches,threshold,repeats):\n",
    "    \n",
    "    # vu que les patchs sont piochés de manière aléatoire à chaque fois, \n",
    "    # j'ai trouvé qu'on obtenait des résultats plus fiables en faisant une moyenne\n",
    "    # des prédictions sur plusieurs essais sur la même image\n",
    "    predicted_list = []\n",
    "    healthy_patches = 0\n",
    "    fragmented_patches = 0\n",
    "    for i in range(repeats):\n",
    "        predicted_list += predictOneImage(path,img_name,size,number_patches,threshold)\n",
    "    \n",
    "    \n",
    "    if len(predicted_list) == 0 :\n",
    "        print(\"No prediction can be made\")\n",
    "        return -1,0,0\n",
    "    consensus_prediction = 0.5\n",
    "    for prediction in predicted_list :\n",
    "        if prediction < 0.5 :\n",
    "            healthy_patches += 1\n",
    "        else :\n",
    "            fragmented_patches += 1\n",
    "        consensus_prediction = bayesian_inference(consensus_prediction, prediction)\n",
    "        \n",
    "        \n",
    "    if consensus_prediction < 0.5:\n",
    "        print(\"prediction : HEALTHY (%s)\"%(1-consensus_prediction))\n",
    "    else :\n",
    "        print(\"prediction : FRAGMENTED (%s)\" %(consensus_prediction))\n",
    "    return consensus_prediction, healthy_patches, fragmented_patches\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictMultiples(path,size,number_patches,threshold,repeats):\n",
    "    csv = \"\"\n",
    "    healthy = 0\n",
    "    fragmented = 0\n",
    "    errors = 0\n",
    "    healthy_patches = 0\n",
    "    fragmented_patches = 0\n",
    "    bayesian_prediction = 0.5\n",
    "    average_prediction = 0\n",
    "    # pour chaque image du répertoire\n",
    "    for img_name in listdir(path) :\n",
    "        res = predictOne_consistent(path,img_name,size,number_patches,threshold,repeats)\n",
    "        healthy_patches += res[1]\n",
    "        fragmented_patches += res[2]\n",
    "        \n",
    "        \"\"\"\n",
    "        # création d'un histogramme\n",
    "        x = np.array([\"Healthy\", \"Fragmented\"])\n",
    "        if(res == -1) :\n",
    "            y = np.array([0,0])\n",
    "        else :\n",
    "            y = np.array([1-res,res])\n",
    "        fig, ax = plt.subplots()\n",
    "        barp = plt.bar(x,y, color=['green', 'red'])\n",
    "        plt.show()\n",
    "        # on ouvre et affiche l'image\n",
    "        im = Image.open(path+\"/\"+img_name)\n",
    "        im = im.resize((488,360), Image.NEAREST)\n",
    "        display(im)\n",
    "        \"\"\"\n",
    "    \n",
    "        csv += img_name + \";\" #Les noms des images contiennent des \",\", ne pas en utiliser comme séparateur\n",
    "        if res[0] == -1 :\n",
    "            csv += \"none;none\"\n",
    "            errors += 1\n",
    "        else :\n",
    "            average_prediction += res [0]\n",
    "            # Inférence Bayésienne :\n",
    "            bayesian_prediction = bayesian_inference(bayesian_prediction, res[0])  \n",
    "            if res[0] < 0.5 :\n",
    "                csv += str(res[0]) + \";healthy\"\n",
    "                healthy += 1\n",
    "            else :\n",
    "                csv += str(res[0]) + \";fragmented\"\n",
    "                fragmented += 1\n",
    "        csv += \";\"+ str(res[1])+ \";\" + str(res[2])+ \"\\n\" \n",
    "        print(\"============================================================\")\n",
    "\n",
    "    average_prediction /= healthy + fragmented\n",
    "    head = \"image;P(fragmented);Prediction;Healthy patches;Fragmented patches \\n\"\n",
    "    \n",
    "    head += \"inférence bayésienne;%s;\" %(bayesian_prediction)\n",
    "    if(bayesian_prediction > 0.5) :\n",
    "        head += \"fragmented;\"\n",
    "    else :\n",
    "        head += \"healthy;\"\n",
    "    head += str(healthy_patches) + \";\" + str(fragmented_patches) + \"\\n\"\n",
    "    \n",
    "    head += \"moyenne;%s;\" %(average_prediction)    \n",
    "    if(average_prediction > 0.5) :\n",
    "        head += \"fragmented;\"\n",
    "    else :\n",
    "        head += \"healthy;\"\n",
    "    head += str(healthy_patches) + \";\" + str(fragmented_patches) + \"\\n\"\n",
    "    \n",
    "    csv = head + csv\n",
    "    print(csv)\n",
    "    \n",
    "    print(f\"il y a eu une prédiction de {healthy} healthy et {fragmented} fragmented sur {healthy + fragmented + errors} images traitées\")\n",
    "    print(\"confiance : %s\" %(bayesian_prediction))\n",
    "    \n",
    "    if(errors >0) :\n",
    "        print(\"Il y a %s images intraitables\" %(errors))\n",
    "        \n",
    "        \n",
    "    fic=open(\"experimental_result.csv\",\"w\")\n",
    "    fic.write(csv)\n",
    "    fic.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No prediction can be made\n",
      "============================================================\n",
      "prediction : FRAGMENTED (0.8867505324354478)\n",
      "============================================================\n",
      "prediction : FRAGMENTED (0.883551102929861)\n",
      "============================================================\n",
      "prediction : HEALTHY (0.583200472652361)\n",
      "============================================================\n",
      "prediction : FRAGMENTED (0.8150021257899118)\n",
      "============================================================\n",
      "prediction : FRAGMENTED (0.5546758912503719)\n",
      "============================================================\n",
      "prediction : HEALTHY (0.6492203395557383)\n",
      "============================================================\n",
      "image;P(fragmented);Prediction;Healthy patches;Fragmented patches \n",
      "inférence bayésienne;0.8239570854578071;fragmented;9;21\n",
      "moyenne;0.6512598066995822;fragmented;9;21\n",
      "E4--1-1-1-Tsf[GFP 469,525]-001.tif;none;none;0;0\n",
      "D3--1-1-1-Tsf[GFP 469,525]-001.tif;0.8867505324354478;fragmented;2;5\n",
      "D2--1-1-1-Tsf[GFP 469,525]-001.tif;0.883551102929861;fragmented;1;5\n",
      "D4--1-1-1-Tsf[GFP 469,525]-001.tif;0.4167995273476391;healthy;3;3\n",
      "D1--1-1-1-Tsf[GFP 469,525]-001.tif;0.8150021257899118;fragmented;0;5\n",
      "E2--1-1-1-Tsf[GFP 469,525]-001.tif;0.5546758912503719;fragmented;0;1\n",
      "E3--1-1-1-Tsf[GFP 469,525]-001.tif;0.35077966044426173;healthy;3;2\n",
      "\n",
      "il y a eu une prédiction de 2 healthy et 4 fragmented sur 7 images traitées\n",
      "confiance : 0.8239570854578071\n",
      "Il y a 1 images intraitables\n"
     ]
    }
   ],
   "source": [
    "path = \"./Data/Images-Cytation/Experiment2_210326/Bad/Prediction\"\n",
    "#path = \"./Data/All_bad\"\n",
    "size = 320\n",
    "number_patches = 10\n",
    "threshold = 3\n",
    "repeats = 10\n",
    "\n",
    "predictMultiples(path,size,number_patches,threshold,repeats)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
